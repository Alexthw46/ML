{
 "cells": [
  {
   "cell_type": "code",
   "id": "425015420664a47f",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import dataset_utils as dataset\n",
    "import torch as t\n",
    "\n",
    "from ML_cup.pytorch import *\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    torch.set_default_device(torch.device(\"cuda\"))\n",
    "print(f\"Using device: {torch.cuda.current_device()}\")\n",
    "print(f\"Available cpu count: {os.cpu_count()}\")\n",
    "\n",
    "# load data\n",
    "dev_data = dataset.load_dataset(\"../data/ML-CUP24-TR.csv\")\n",
    "blind_data = dataset.load_dataset(\"../data/ML-CUP24-TS.csv\")\n",
    "dev_data, X_scaler, y_scaler = dataset.rescale_dataset(dev_data)\n",
    "blind_data = dataset.rescale_dataset(blind_data, X_scaler)\n",
    "\n",
    "rand = 1741091302\n",
    "np.random.seed(rand)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split the dev data into train and validation with k-fold cross validation\n",
    "train_loaders, val_loaders, dev_loader, test_loader = dataset.torch_k_fold(dataset=dev_data, folds=5, batch_size=0)\n",
    "# blind test\n",
    "from ML_cup.dataset_utils import CupDataset\n",
    "\n",
    "blind_loader = DataLoader(CupDataset(blind_data, device=torch.device('cuda')), batch_size=len(blind_data))"
   ],
   "id": "34e56bb290bee34e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lr = 0.0001\n",
    "weight_decay = 0.0005\n",
    "\n",
    "def MLP() -> t.nn.Module:\n",
    "    return t.nn.Sequential(\n",
    "        t.nn.Linear(12, 200),\n",
    "        t.nn.Tanh(),\n",
    "        t.nn.Linear(200, 200),\n",
    "        t.nn.Tanh(),\n",
    "        t.nn.Linear(200, 3)\n",
    "    )\n",
    "\n",
    "# test different seeds in kfold\n",
    "seeds = [rand / 10, rand / 2, rand, rand * 2, rand * 10]\n",
    "\n",
    "train_mee_across_seeds = []\n",
    "val_mee_across_seeds = []\n",
    "test_mee_across_seeds = []\n",
    "\n",
    "for seed in seeds:\n",
    "    train_mee_seed = []\n",
    "    val_mee_seed = []\n",
    "    for train_loader, val_loader in zip(train_loaders, val_loaders):\n",
    "        t.manual_seed(seed)\n",
    "        model = MLP()\n",
    "        optimizer = t.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        _, _, train_mee, val_mee, _, _ = torch_train(model, train_loader, optimizer, epochs=1000, val_loader=val_loader,\n",
    "                                                     verbose=False, return_last=True, y_scaler=y_scaler,\n",
    "                                                     random_seed=seed, patience=5, skip_plot_points=0,\n",
    "                                                     clip=1.0)\n",
    "        train_mee_seed.append(train_mee)\n",
    "        val_mee_seed.append(val_mee)\n",
    "    avg_train_mee = np.mean(train_mee_seed)\n",
    "    avg_val_mee = np.mean(val_mee_seed)\n",
    "    train_mee_across_seeds.append(avg_train_mee)\n",
    "    val_mee_across_seeds.append(avg_val_mee)\n",
    "\n",
    "print(f\"Train MEE: {train_mee_across_seeds}, Mean: {np.mean(train_mee_across_seeds)}\")\n",
    "print(f\"Validation MEE: {val_mee_across_seeds}, Mean: {np.mean(val_mee_across_seeds)}\")"
   ],
   "id": "e0ea3b91d605f011",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pick the best seed, more details on the fold results\n",
    "seed = rand / 2\n",
    "train_mee_seed = []\n",
    "val_mee_seed = []\n",
    "for train_loader, val_loader in zip(train_loaders, val_loaders):\n",
    "    t.manual_seed(seed)\n",
    "    model = MLP()\n",
    "    optimizer = t.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    _, _, train_mee, val_mee, _, _ = torch_train(model, train_loader, optimizer, epochs=1000, val_loader=val_loader,\n",
    "                                                 verbose=False, return_last=True, y_scaler=y_scaler,\n",
    "                                                 random_seed=seed, patience=5, skip_plot_points=0,\n",
    "                                                 clip=1.0)\n",
    "    train_mee_seed.append(train_mee)\n",
    "    val_mee_seed.append(val_mee)\n",
    "\n",
    "print(train_mee_seed)\n",
    "print(val_mee_seed)"
   ],
   "id": "a91ab571466809dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_loader = train_loaders[3]\n",
    "val_loader = val_loaders[3]\n",
    "t.manual_seed(seed)\n",
    "model = MLP()\n",
    "optimizer = t.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "train_loss, val_loss, train_mee, val_mee, _, model = torch_train(model, train_loader, optimizer, epochs=1000,\n",
    "                                                                 val_loader=val_loader,\n",
    "                                                                 verbose=True, return_last=True, y_scaler=y_scaler,\n",
    "                                                                 random_seed=seed, patience=5, skip_plot_points=100,\n",
    "                                                                 clip=1.0)\n",
    "\n",
    "print(f\"Train MEE: {train_mee}, Validation MEE: {val_mee}\")\n",
    "print(f\"Train Loss: {train_loss}, Validation Loss: {val_loss}\")\n"
   ],
   "id": "9b3f287eb2fd0621",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# run model on test\n",
    "print(\"Evaluating the model on the test set\")\n",
    "print(torch_predict(model, test_loader, y_scaler=y_scaler))"
   ],
   "id": "284a14c5877ac7c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predictions = blind_test(model, blind_loader, seed, y_scaler=y_scaler)",
   "id": "3ea37ec937969b87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# save predictions into csv\n",
    "np.savetxt('predictions.csv', predictions, delimiter=',', fmt='%f')"
   ],
   "id": "1f0fd8f73760cb40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file using numpy\n",
    "predictions = np.loadtxt('predictions.csv', delimiter=',')\n",
    "\n",
    "# Convert the numpy array to a pandas DataFrame\n",
    "df = pd.DataFrame(predictions)\n",
    "\n",
    "# Add an index column (you can name it 'Index')\n",
    "df['Index'] = df.index\n",
    "df = df[['Index'] + [col for col in df.columns if col != 'Index']]\n",
    "\n",
    "# Save the new CSV with the index column\n",
    "df.to_csv('MAG_ML-CUP24-TS.csv', index=False)"
   ],
   "id": "b00d0e846d5100df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a506b5c67bf6f246",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
