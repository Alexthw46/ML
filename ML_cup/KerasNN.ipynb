{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-29T14:00:28.412608Z",
     "start_time": "2024-07-29T14:00:23.455087Z"
    }
   },
   "source": [
    "import dataset_utils as dataset\n",
    "\n",
    "from Keras import *\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from dataset_utils import arrange_datasets, train_val_kfold"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# check if the gpu is available\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"No GPU available. Using CPU instead.\")\n",
    "\n",
    "print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T14:00:28.755776Z",
     "start_time": "2024-07-29T14:00:28.413906Z"
    }
   },
   "id": "28ab79d60582d0e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n",
      "GPU name:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "dev_data = dataset.load_dataset(\"../data/ML-CUP23-TR.csv\")\n",
    "blind_data = dataset.load_dataset(\"../data/ML-CUP23-TS.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T14:00:28.776317Z",
     "start_time": "2024-07-29T14:00:28.756774Z"
    }
   },
   "id": "b87130321fcb4b33",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "seed = 18\n",
    "# split the two dataset into inputs and labels, scale them, then kfold the devset for grid search\n",
    "X, y, X_blind = arrange_datasets(dev_data, blind_data)\n",
    "\n",
    "# train-val-test split on devset\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, train_size=0.85, random_state=seed, shuffle=True)\n",
    "train_folds, val_folds = train_val_kfold(X_dev, y_dev, folds=5, random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.3, random_state=seed, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T14:00:28.782420Z",
     "start_time": "2024-07-29T14:00:28.777246Z"
    }
   },
   "id": "aec92c8044e4ec46",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Keras"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "828322c2741087d1"
  },
  {
   "cell_type": "code",
   "source": [
    "parameters = [\n",
    "    {'optimizer': 'SGD', 'learning_rate': [0.005, 0.0025, 0.001, 0.0001],\n",
    "     'weight_decay': [0.0, 0.001, 0.0005, 0.0001],\n",
    "     'momentum': [0.9, 0.75], 'nesterov': [True, False]}\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T14:00:28.786267Z",
     "start_time": "2024-07-29T14:00:28.783898Z"
    }
   },
   "id": "457a9ecdd98484f7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "prev_best = (1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T14:00:28.789350Z",
     "start_time": "2024-07-29T14:00:28.787147Z"
    }
   },
   "id": "fc78d77c6caf3664",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "def grid(treshhold, layer_configuration):\n",
    "    new_best = prev_best = treshhold\n",
    "    print(f\"Layer configuration: {layer_configuration}\")\n",
    "    best_keras_params, res_values = keras_grid_search(model_builder=keras_mlp, parameters=parameters,\n",
    "                                                      model_layers=layer_configuration,\n",
    "                                                      train_data=train_folds, val_data=val_folds,\n",
    "                                                      verbose=0, max_epochs=200, best_values=prev_best)\n",
    "    if res_values[0] < prev_best[0] and res_values[1] < prev_best[1]:\n",
    "        new_best = res_values\n",
    "\n",
    "    print(f\"Best combo: {best_keras_params}, with values: {new_best}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T14:00:28.792680Z",
     "start_time": "2024-07-29T14:00:28.790232Z"
    }
   },
   "id": "5ecbe538e6ca867c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "layers = [\n",
    "    ('dense', 200),\n",
    "    ('dense', 200)\n",
    "]\n",
    "grid(prev_best, layers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-29T15:11:33.245597Z",
     "start_time": "2024-07-29T14:00:28.793563Z"
    }
   },
   "id": "d39cbc80ea03f125",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer configuration: [('dense', 200), ('dense', 200)]\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722261630.067539     140 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: mean - 0.07585861012339593 std - 0.022297762719587957, Val Loss: mean - 0.3508461654186249 std - 0.040797248925533526\n",
      "--------------------------------\n",
      "New best parameters\n",
      "--------------------------------\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.09956855773925781 std - 0.020860350639255593, Val Loss: mean - 0.4986847400665283 std - 0.1035445859711427\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.29133234918117523 std - 0.06060715114808233, Val Loss: mean - 0.6007025063037872 std - 0.1852731737193075\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.14393973648548125 std - 0.023217800102151732, Val Loss: mean - 0.30509832203388215 std - 0.049708104089788555\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.0726016953587532 std - 0.00508975734405886, Val Loss: mean - 0.3363694608211517 std - 0.046071099821459204\n",
      "--------------------------------\n",
      "New best parameters\n",
      "--------------------------------\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.08524740412831307 std - 0.030019500900317398, Val Loss: mean - 0.41392749547958374 std - 0.06847196638403677\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.22504369914531708 std - 0.030337146408650602, Val Loss: mean - 0.5265234172344208 std - 0.12239382163302696\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.21428822875022888 std - 0.08760061652110537, Val Loss: mean - 0.3925349354743958 std - 0.06808776696387897\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.07752948701381683 std - 0.03055347909287711, Val Loss: mean - 0.3615421712398529 std - 0.06740171732678882\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.08984025120735169 std - 0.024800481818489248, Val Loss: mean - 0.5082826316356659 std - 0.1550756991034405\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.38390532732009885 std - 0.11213372545871393, Val Loss: mean - 0.724434232711792 std - 0.16673030655901033\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.1555822253227234 std - 0.012304354019692432, Val Loss: mean - 0.33396796584129335 std - 0.04116564856891488\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.0864773616194725 std - 0.01972798080294899, Val Loss: mean - 0.35634455978870394 std - 0.0762222682753149\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.07945217862725258 std - 0.014143624466316139, Val Loss: mean - 0.47187580466270446 std - 0.08936110946739671\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.25867147743701935 std - 0.09207722251147128, Val Loss: mean - 0.5234984517097473 std - 0.1754145188839699\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.2573950171470642 std - 0.09705024228525377, Val Loss: mean - 0.42916221618652345 std - 0.11630137154528665\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.09239018559455872 std - 0.014266137426580993, Val Loss: mean - 0.29150783717632295 std - 0.047304227219019945\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.11535855680704117 std - 0.026331572009412756, Val Loss: mean - 0.3471741914749146 std - 0.07871705758029278\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.29645314514636995 std - 0.07281796129204889, Val Loss: mean - 0.529379940032959 std - 0.10486910171364958\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.23138737976551055 std - 0.03271990954425014, Val Loss: mean - 0.4251720249652863 std - 0.06948791150552731\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.11160802692174912 std - 0.020802967875867447, Val Loss: mean - 0.3088089108467102 std - 0.06722354684532293\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.1045072466135025 std - 0.031862356369319396, Val Loss: mean - 0.3062804937362671 std - 0.0349863138148929\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.326120188832283 std - 0.05902889997770417, Val Loss: mean - 0.5834022521972656 std - 0.11042228828379899\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.2555444300174713 std - 0.07049990480230192, Val Loss: mean - 0.468299126625061 std - 0.1471948082050017\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.09441088885068893 std - 0.021609494007899948, Val Loss: mean - 0.2810481369495392 std - 0.025617968585599955\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.10940721929073334 std - 0.016530795030930058, Val Loss: mean - 0.3413115978240967 std - 0.07664906676599066\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.3358262151479721 std - 0.0992505206155441, Val Loss: mean - 0.5571415483951568 std - 0.10727907924991902\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.2771217703819275 std - 0.0753695629028393, Val Loss: mean - 0.4704284131526947 std - 0.11333147454357752\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.12455840706825257 std - 0.03994388825391717, Val Loss: mean - 0.33559752702713014 std - 0.09446814477998329\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.10060207694768905 std - 0.015206282824105383, Val Loss: mean - 0.33947799205780027 std - 0.10211370683109813\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.34362887144088744 std - 0.06814075378335778, Val Loss: mean - 0.5812756299972535 std - 0.0979013160106458\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.2389699101448059 std - 0.0785332634909022, Val Loss: mean - 0.44318422079086306 std - 0.08818560092352053\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.16478547751903533 std - 0.003291698436260577, Val Loss: mean - 0.3363426268100739 std - 0.04091384539896462\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.1810364007949829 std - 0.023757149986446607, Val Loss: mean - 0.36026450991630554 std - 0.07657346859912795\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.4395984709262848 std - 0.012427226200082632, Val Loss: mean - 0.6317272305488586 std - 0.06904072596168238\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.44237574338912966 std - 0.027714746383025294, Val Loss: mean - 0.6589130640029908 std - 0.09910209634293818\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.1641840696334839 std - 0.00826985908739029, Val Loss: mean - 0.3565851390361786 std - 0.0564739793375647\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.1595034956932068 std - 0.00539288498245068, Val Loss: mean - 0.3382006824016571 std - 0.05575186798050667\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.4511237025260925 std - 0.02354987562157097, Val Loss: mean - 0.668507719039917 std - 0.05533171349171273\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.44843459129333496 std - 0.02449354199051248, Val Loss: mean - 0.6449705123901367 std - 0.04972144980280518\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.18139179646968842 std - 0.03660328756716347, Val Loss: mean - 0.34339392781257627 std - 0.04738143320807539\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.17386199831962584 std - 0.02078731642164085, Val Loss: mean - 0.3567057251930237 std - 0.036650006110714076\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.44882604479789734 std - 0.02746727392449631, Val Loss: mean - 0.6449590682983398 std - 0.056948209543534634\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.43640350699424746 std - 0.007894609689567803, Val Loss: mean - 0.6291337132453918 std - 0.06802576765490059\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.19413969218730925 std - 0.039426844965964575, Val Loss: mean - 0.367950838804245 std - 0.0351211615786838\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.17076321244239806 std - 0.022169851343124856, Val Loss: mean - 0.342286616563797 std - 0.03955827832103758\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.4326926052570343 std - 0.014417109360250771, Val Loss: mean - 0.6354600548744201 std - 0.071311905512388\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.4469173073768616 std - 0.012541980169898366, Val Loss: mean - 0.635277783870697 std - 0.06889998805267267\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 2.1416327476501467 std - 0.04986696330643614, Val Loss: mean - 2.4209585189819336 std - 0.3557761055417849\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 2.1363263607025145 std - 0.04502695694672703, Val Loss: mean - 2.415699768066406 std - 0.34663050984498794\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 4.962760066986084 std - 0.10435002444931649, Val Loss: mean - 5.315623188018799 std - 0.7941702058093407\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 4.966528511047363 std - 0.09968525328229089, Val Loss: mean - 5.313028621673584 std - 0.7876544762663007\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 2.134644317626953 std - 0.05702565390824311, Val Loss: mean - 2.414362096786499 std - 0.3649366615629987\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 2.128066349029541 std - 0.04817492458927376, Val Loss: mean - 2.4130921363830566 std - 0.3553469638419022\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 4.970089721679687 std - 0.09766250814636374, Val Loss: mean - 5.3306553840637205 std - 0.7970447891119962\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 4.963817691802978 std - 0.09977459155493247, Val Loss: mean - 5.304485893249511 std - 0.7896592426762981\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 2.1315891265869142 std - 0.04602862866051137, Val Loss: mean - 2.4100462913513185 std - 0.35986800265746144\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 2.1358296394348146 std - 0.04951449828773803, Val Loss: mean - 2.4111003160476683 std - 0.3565584918216191\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 4.969844818115234 std - 0.1006909859610495, Val Loss: mean - 5.317154026031494 std - 0.7915563075414237\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 4.968188095092773 std - 0.10110250786733861, Val Loss: mean - 5.326426315307617 std - 0.7865488350263942\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 2.1249029636383057 std - 0.05258864653540399, Val Loss: mean - 2.398942756652832 std - 0.35789067576405836\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 2.1368923664093016 std - 0.052689994493953535, Val Loss: mean - 2.4115827560424803 std - 0.35917317109555313\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 4.969222736358643 std - 0.09861421931817067, Val Loss: mean - 5.308094596862793 std - 0.7896039952609932\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 4.962950611114502 std - 0.09456675636404864, Val Loss: mean - 5.314052963256836 std - 0.7858875489671067\n",
      "Best Parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True, 'optimizer': 'SGD'}, Train Loss: 0.07514657403078263, Val Loss: 0.3594050107318813\n",
      "Best combo: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True, 'optimizer': 'SGD'}, with values: (0.07514657403078263, 0.3594050107318813)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "layers = [\n",
    "    ('dense', 25),\n",
    "    ('dense', 50),\n",
    "    ('dense', 150)\n",
    "]\n",
    "grid(prev_best, layers)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-29T15:11:33.247106Z"
    }
   },
   "id": "96865d55fb40cded",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer configuration: [('dense', 25), ('dense', 50), ('dense', 150)]\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.1404857635498047 std - 0.05896111916474787, Val Loss: mean - 0.5533400774002075 std - 0.22615236576521514\n",
      "--------------------------------\n",
      "New best parameters\n",
      "--------------------------------\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.20047926604747773 std - 0.0701104820514447, Val Loss: mean - 0.836604630947113 std - 0.27914232610635864\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.357501482963562 std - 0.15392222829402671, Val Loss: mean - 0.7077323257923126 std - 0.21272417754259665\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.3378247499465942 std - 0.06776313566180751, Val Loss: mean - 0.7890731275081635 std - 0.26063252389325997\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.1672238290309906 std - 0.06410096521691497, Val Loss: mean - 0.8920202612876892 std - 0.27878688731782325\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.203334541618824 std - 0.09645703950517896, Val Loss: mean - 0.7929880261421204 std - 0.21371373766631857\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.3478906065225601 std - 0.1101761350858972, Val Loss: mean - 0.7755996227264405 std - 0.174011848291727\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.3429014414548874 std - 0.1591721354073559, Val Loss: mean - 0.636489874124527 std - 0.1520667657851516\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.16568745970726012 std - 0.05299282645231994, Val Loss: mean - 0.7676735639572143 std - 0.23648266648942234\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.16960725486278533 std - 0.0853157410161162, Val Loss: mean - 0.8576680660247803 std - 0.30287893176734126\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.38540705740451814 std - 0.13202631670567724, Val Loss: mean - 0.8650447487831116 std - 0.1963490495655055\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.3066332101821899 std - 0.11225245173746869, Val Loss: mean - 0.6644377827644348 std - 0.22307788615375004\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.15459026545286178 std - 0.08851349720549176, Val Loss: mean - 0.6720501363277436 std - 0.2733747198293454\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.13961318135261536 std - 0.02906263794017019, Val Loss: mean - 0.8695406794548035 std - 0.07701521414371618\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.3531886458396912 std - 0.13616946005872776, Val Loss: mean - 1.0294061660766602 std - 0.4951794244688165\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.3447927862405777 std - 0.1073763775229163, Val Loss: mean - 0.7266428530216217 std - 0.3080343382853557\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.1794369637966156 std - 0.06802211057710422, Val Loss: mean - 0.48960822224617007 std - 0.1294998392057328\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.16494649797677993 std - 0.04155395115131619, Val Loss: mean - 0.45938599705696104 std - 0.0804641626975858\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.4707065224647522 std - 0.10048329600983145, Val Loss: mean - 0.8391564130783081 std - 0.2440417812723266\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.3718447327613831 std - 0.057004857986456, Val Loss: mean - 0.6961146831512451 std - 0.08490535000343226\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.18537060618400575 std - 0.08727070931789309, Val Loss: mean - 0.4504961907863617 std - 0.06615580342844202\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.15615902543067933 std - 0.046252045901220416, Val Loss: mean - 0.4554153859615326 std - 0.03454363848998439\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.4338566303253174 std - 0.1107452214208498, Val Loss: mean - 0.7714823246002197 std - 0.12546623236446158\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.47299751341342927 std - 0.1263767593446623, Val Loss: mean - 0.8702245354652405 std - 0.2729060905077992\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.15354491025209427 std - 0.03834406316149981, Val Loss: mean - 0.4128402590751648 std - 0.11767266915965026\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.1905332997441292 std - 0.044475513548096125, Val Loss: mean - 0.5152307033538819 std - 0.13543016101536712\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.4376486957073212 std - 0.17614939347748101, Val Loss: mean - 0.8116369783878327 std - 0.3120684497153519\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.4769915878772736 std - 0.22137865025679154, Val Loss: mean - 0.7002540588378906 std - 0.12939010110940694\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.12230828255414963 std - 0.03068372788923787, Val Loss: mean - 0.36573231816291807 std - 0.05034131501881233\n",
      "--------------------------------\n",
      "New best parameters\n",
      "--------------------------------\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.15839684158563613 std - 0.06280898085293203, Val Loss: mean - 0.3903204739093781 std - 0.05224186024377877\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.4279747545719147 std - 0.09091670563919607, Val Loss: mean - 0.9543258786201477 std - 0.23971120474935242\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.4029597580432892 std - 0.07150043056186017, Val Loss: mean - 0.6490334868431091 std - 0.06365791299339384\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: mean - 0.22648173868656157 std - 0.05839048227825179, Val Loss: mean - 0.4385651409626007 std - 0.05254585493266586\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: mean - 0.23552410304546356 std - 0.05340961122385292, Val Loss: mean - 0.43962759971618653 std - 0.027996949504171573\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: mean - 0.5886598527431488 std - 0.10805116787893276, Val Loss: mean - 0.9487274169921875 std - 0.19146259104980895\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: mean - 0.5651637971401214 std - 0.08103492626491272, Val Loss: mean - 0.8506691217422485 std - 0.12100276420604271\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model_to_test = keras_mlp([\n",
    "    ('dense', 25),\n",
    "    ('dense', 50),\n",
    "    ('dense', 150)\n",
    "])\n",
    "#Best combo: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True, 'optimizer': 'SGD'}, with values: (0.05887814909219742, 0.43884475231170655)\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, cooldown=10, verbose=1,\n",
    "                      factor=0.5,\n",
    "                      min_lr=1e-7,\n",
    "                      min_delta=1e-7),\n",
    "    EarlyStopping(monitor='val_loss', start_from_epoch=100, patience=20,\n",
    "                  min_delta=1e-7)\n",
    "]\n",
    "optim = k.optimizers.SGD(learning_rate=0.0045, momentum=0.9, weight_decay=0.000, nesterov=True)\n",
    "hst = keras_train(model_to_test, train_data=(X_train, y_train), val_data=(X_val, y_val), epochs=350, batch_size=50,\n",
    "                  optimizer=optim, callback=callbacks)\n",
    "plot_keras_history(hst, 20)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "47b628268cfe7a22",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "grid(prev_best, [\n",
    "    ('dense', 150),\n",
    "    ('dense', 50),\n",
    "    ('dense', 25)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "fe268f998e3f5eb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model_to_test = keras_mlp([\n",
    "    ('dense', 150),\n",
    "    ('dense', 50),\n",
    "    ('dense', 25)\n",
    "])\n",
    "\n",
    "optim = k.optimizers.SGD(learning_rate=0.01, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "\n",
    "hst = keras_train(model_to_test, train_data=(X_train, y_train), val_data=(X_val, y_val), epochs=150, batch_size=50,\n",
    "                  optimizer=optim, callback=callbacks)\n",
    "\n",
    "plot_keras_history(hst)\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "80c4f89690b9d04",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "c6ef81bfe4c05ab6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "grid(prev_best, [\n",
    "    ('dense', 300),\n",
    "    ('dense', 300),\n",
    "    ('dense', 300),\n",
    "    ('dense', 300)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "e3ddc94c1f77cef1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "grid(prev_best, [\n",
    "    ('dense', 500),\n",
    "    ('dense', 500),\n",
    "    ('dense', 300),\n",
    "    ('dense', 300),\n",
    "    ('dense', 150),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "bfd22fa3a339d4dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#Best parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True, 'optimizer': 'SGD'}, with values: (18.03679656982422, 18.47313709259033)\n",
    "model_to_test = keras_mlp([\n",
    "    ('bn', 1),\n",
    "    ('dense', 300),\n",
    "    ('dense', 300),\n",
    "    ('dense', 300),\n",
    "    ('dense', 300)\n",
    "])\n",
    "model_to_test.summary()\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, cooldown=20, verbose=1,\n",
    "                      factor=0.25,\n",
    "                      min_lr=1e-7,\n",
    "                      min_delta=1e-7)\n",
    "]\n",
    "history = keras_train(model_to_test, train_data=(X_train, y_train), val_data=(X_val, y_val), epochs=150,\n",
    "                      optimizer=k.optimizers.SGD(learning_rate=0.005, momentum=0.9, weight_decay=0.001, nesterov=True),\n",
    "                      callback=callbacks)\n",
    "plot_keras_history(history)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "9ff7274805279b14",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "model_to_test = keras_mlp([\n",
    "    ('dense', 350),\n",
    "    ('dense', 350),\n",
    "    ('dense', 150),\n",
    "    ('dense', 150),\n",
    "])\n",
    "\n",
    "\n",
    "def scheduler(epochs, lr):\n",
    "    newlr = lr\n",
    "    if epochs % 100 == 0:\n",
    "        newlr = lr * 0.5\n",
    "    return newlr\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    LearningRateScheduler(scheduler)\n",
    "]\n",
    "#Best combo: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True, 'optimizer': 'SGD'}, with values: (0.0807236298918724, 0.35102823972702024)\n",
    "\n",
    "optim = k.optimizers.SGD(learning_rate=0.001, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "hst = keras_train(model_to_test, train_data=(X_train, y_train), val_data=(X_val, y_val), epochs=350,\n",
    "                  optimizer=optim, callback=callbacks)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "b2a580e850e748b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plot_keras_history(hst, 30)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "4e7734c7ada71066",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "eaa1a7ba3d191a80",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "6a69341138b351f1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
