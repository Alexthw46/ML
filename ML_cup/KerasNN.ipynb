{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-18T11:29:59.587868100Z",
     "start_time": "2024-01-18T11:29:55.184917700Z"
    }
   },
   "outputs": [],
   "source": [
    "import dataset_utils as dataset\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from Keras import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from dataset_utils import arange_datasets, train_val_kfold"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T11:29:59.595106200Z",
     "start_time": "2024-01-18T11:29:59.587868100Z"
    }
   },
   "id": "28ab79d60582d0e0",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dev_data = dataset.load_dataset(\"../data/ML-CUP23-TR.csv\")\n",
    "blind_data = dataset.load_dataset(\"../data/ML-CUP23-TS.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T11:29:59.607683300Z",
     "start_time": "2024-01-18T11:29:59.589919200Z"
    }
   },
   "id": "b87130321fcb4b33",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "seed = 18\n",
    "# split the two dataset into inputs and labels, scale them, then kfold the devset for grid search\n",
    "X, y, X_blind = arange_datasets(dev_data, blind_data)\n",
    "\n",
    "# train-val-test split on devset\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, train_size=0.85, random_state=seed, shuffle=True)\n",
    "train_folds, val_folds = train_val_kfold(X_dev, y_dev, folds=5, random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.3, random_state=seed, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T11:29:59.654365700Z",
     "start_time": "2024-01-18T11:29:59.610314300Z"
    }
   },
   "id": "aec92c8044e4ec46",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Keras"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "828322c2741087d1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {'optimizer': 'SGD', 'learning_rate': [0.005, 0.0025, 0.001, 0.0001],\n",
    "     'weight_decay': [0.0, 0.001, 0.0005, 0.0001],\n",
    "     'momentum': [0.9, 0.75], 'nesterov': [True, False]}\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T11:30:00.438353Z",
     "start_time": "2024-01-18T11:30:00.432830900Z"
    }
   },
   "id": "457a9ecdd98484f7",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prev_best = (1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T11:30:02.485677Z",
     "start_time": "2024-01-18T11:30:02.479344800Z"
    }
   },
   "id": "fc78d77c6caf3664",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def grid(treshhold, layer_configuration):\n",
    "    new_best = prev_best = treshhold\n",
    "    print(f\"Layer configuration: {layer_configuration}\")\n",
    "    best_keras_params, res_values = keras_grid_search(model_builder=keras_mlp, parameters=parameters,\n",
    "                                                      model_layers=layer_configuration,\n",
    "                                                      train_data=train_folds, val_data=val_folds,\n",
    "                                                      verbose=0, max_epochs=200, best_values=prev_best)\n",
    "    if res_values[0] < prev_best[0] and res_values[1] < prev_best[1]:\n",
    "        new_best = res_values\n",
    "\n",
    "    print(f\"Best combo: {best_keras_params}, with values: {new_best}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T11:30:03.879778100Z",
     "start_time": "2024-01-18T11:30:03.834928400Z"
    }
   },
   "id": "5ecbe538e6ca867c",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer configuration: [('dense', 200), ('dense', 200)]\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.virtualenvs/ML/lib/python3.10/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer Orthogonal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705489112.006414 1564874 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.05067068189382553, Val Loss: 0.2952613592147827\n",
      "--------------------------------\n",
      "New best parameters\n",
      "--------------------------------\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.051228144019842145, Val Loss: 0.42931469678878786\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.15304337292909623, Val Loss: 0.335204017162323\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.1232564851641655, Val Loss: 0.304096919298172\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.06071796342730522, Val Loss: 0.32038230895996095\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.04753293171525001, Val Loss: 0.4538374781608582\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.16303852945566177, Val Loss: 0.36282750964164734\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.1318461924791336, Val Loss: 0.3152294337749481\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.05521119311451912, Val Loss: 0.31255834102630614\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.04284955039620399, Val Loss: 0.43000946640968324\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.14915806651115418, Val Loss: 0.34215071201324465\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.13473640829324723, Val Loss: 0.32354078590869906\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.04766896441578865, Val Loss: 0.2898890256881714\n",
      "--------------------------------\n",
      "New best parameters\n",
      "--------------------------------\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.047168150544166565, Val Loss: 0.4729833483695984\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.1674204170703888, Val Loss: 0.3507002770900726\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.14994188249111176, Val Loss: 0.3466233372688293\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.07358598709106445, Val Loss: 0.2586085468530655\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.06774534583091736, Val Loss: 0.28530746400356294\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.21673258244991303, Val Loss: 0.4081100046634674\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.20827978551387788, Val Loss: 0.4078236401081085\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.08108594566583634, Val Loss: 0.2648362159729004\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.06784626841545105, Val Loss: 0.2893232762813568\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.24799126088619233, Val Loss: 0.4416196346282959\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.23881042897701263, Val Loss: 0.423615163564682\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.08260688632726669, Val Loss: 0.2781973272562027\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.07075880765914917, Val Loss: 0.294184485077858\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.25936324894428253, Val Loss: 0.4547080099582672\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.22584395706653596, Val Loss: 0.4230266809463501\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.07241248562932015, Val Loss: 0.2670078486204147\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.06524647250771523, Val Loss: 0.2794479846954346\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.2440417230129242, Val Loss: 0.4390920877456665\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.21403655111789704, Val Loss: 0.4074332475662231\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.1659321129322052, Val Loss: 0.36602665185928346\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.1666566401720047, Val Loss: 0.35223324298858644\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.4280915200710297, Val Loss: 0.6306396484375\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.42054460048675535, Val Loss: 0.6303022503852844\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.17180581092834474, Val Loss: 0.36758995056152344\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.16378517746925353, Val Loss: 0.3592784821987152\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.42614996433258057, Val Loss: 0.6298928618431091\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.42313284873962403, Val Loss: 0.6252470254898072\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.1687466949224472, Val Loss: 0.3597452461719513\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.17669081389904023, Val Loss: 0.367811781167984\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.42530584931373594, Val Loss: 0.6368402242660522\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.4200257003307343, Val Loss: 0.6331980228424072\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.16835690438747405, Val Loss: 0.35220734477043153\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.16935809552669526, Val Loss: 0.37018701434135437\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.4208932399749756, Val Loss: 0.6286868929862977\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.4157328844070435, Val Loss: 0.6257823824882507\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 2.095880222320557, Val Loss: 2.3545416355133058\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 2.096369743347168, Val Loss: 2.3634737014770506\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 4.873061752319336, Val Loss: 5.202490234375\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 4.8656840324401855, Val Loss: 5.201822090148926\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 2.0938719272613526, Val Loss: 2.357505774497986\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 2.0920387268066407, Val Loss: 2.3571442365646362\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 4.8717796325683596, Val Loss: 5.209757518768311\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 4.869566535949707, Val Loss: 5.205785179138184\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 2.0968958377838134, Val Loss: 2.3656530141830445\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 2.097446155548096, Val Loss: 2.363892436027527\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 4.868426895141601, Val Loss: 5.2047501564025875\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 4.873518466949463, Val Loss: 5.212299633026123\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 2.090090608596802, Val Loss: 2.3565985918045045\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 2.086088991165161, Val Loss: 2.351940131187439\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 4.872643566131591, Val Loss: 5.215231132507324\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 4.868433856964112, Val Loss: 5.20800142288208\n",
      "Best Parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True, 'optimizer': 'SGD'}, Train Loss: 0.04766896441578865, Val Loss: 0.2898890256881714\n",
      "Best combo: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True, 'optimizer': 'SGD'}, with values: (0.04766896441578865, 0.2898890256881714)\n"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "        ('dense', 200),\n",
    "        ('dense', 200)\n",
    "    ]\n",
    "grid(prev_best, layers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T12:49:45.370361700Z",
     "start_time": "2024-01-17T10:58:31.090524500Z"
    }
   },
   "id": "d39cbc80ea03f125",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer configuration: [('dense', 25), ('dense', 50), ('dense', 150)]\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.07463411912322045, Val Loss: 0.604947304725647\n",
      "--------------------------------\n",
      "New best parameters\n",
      "--------------------------------\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.05180114805698395, Val Loss: 0.7076589524745941\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.14916541874408723, Val Loss: 0.3736623048782349\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.14544326066970825, Val Loss: 0.3831360340118408\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.05538347512483597, Val Loss: 0.6473269104957581\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.05739189684391022, Val Loss: 0.720275092124939\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.14662374705076217, Val Loss: 0.3908554434776306\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.15279619693756102, Val Loss: 0.3660612523555756\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.06066360622644425, Val Loss: 0.6565715730190277\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.051506143808364865, Val Loss: 0.6735996246337891\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.14985589683055878, Val Loss: 0.4053224682807922\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.12321342825889588, Val Loss: 0.36014679074287415\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.05155582129955292, Val Loss: 0.6249679088592529\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.06588985696434975, Val Loss: 0.7943041205406189\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.12734827697277068, Val Loss: 0.3630641996860504\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.14758555144071578, Val Loss: 0.3777106285095215\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.0758421391248703, Val Loss: 0.274834007024765\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.08117970377206803, Val Loss: 0.35185582637786866\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.22821981310844422, Val Loss: 0.4532099008560181\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.2180124282836914, Val Loss: 0.4483747124671936\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.0813985824584961, Val Loss: 0.29943752884864805\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.08368944376707077, Val Loss: 0.3734304666519165\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.24763852059841157, Val Loss: 0.46308977603912355\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.25552946925163267, Val Loss: 0.48698331117630006\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.08519317656755447, Val Loss: 0.30405081510543824\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.07320117354393005, Val Loss: 0.361407995223999\n",
      "--------------------------------\n",
      "New best parameters\n",
      "--------------------------------\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.265727174282074, Val Loss: 0.48906593322753905\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.2220104604959488, Val Loss: 0.42995481491088866\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.08443890139460564, Val Loss: 0.28602121472358705\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.08594906032085418, Val Loss: 0.3698689877986908\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.2650414198637009, Val Loss: 0.48599703311920167\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.24578912258148194, Val Loss: 0.4822044312953949\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.2049279749393463, Val Loss: 0.44070152640342714\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.1820198714733124, Val Loss: 0.39774705171585084\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.4592497944831848, Val Loss: 0.6877440333366394\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.4225763440132141, Val Loss: 0.6440184712409973\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.2038840264081955, Val Loss: 0.44477586150169374\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.19644207060337066, Val Loss: 0.43835790157318116\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.42301369905471803, Val Loss: 0.6353617668151855\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.45101417899131774, Val Loss: 0.6746937394142151\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.2087523877620697, Val Loss: 0.43762264847755433\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.21081117987632753, Val Loss: 0.43898783922195433\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.45250014066696165, Val Loss: 0.6845384955406189\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.45015349984169006, Val Loss: 0.6808692455291748\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.22227055430412293, Val Loss: 0.4626636624336243\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.20222924053668975, Val Loss: 0.44115681648254396\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.4582052528858185, Val Loss: 0.6941741228103637\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.4032682657241821, Val Loss: 0.6351383686065674\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 1.4226264715194703, Val Loss: 1.7472656488418579\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 1.5176705837249755, Val Loss: 1.8266176223754882\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 4.116892719268799, Val Loss: 4.478163433074951\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 4.132477188110352, Val Loss: 4.48455319404602\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 1.4360717058181762, Val Loss: 1.7495248317718506\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 1.4880197286605834, Val Loss: 1.8070789098739624\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 4.116317558288574, Val Loss: 4.479739189147949\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 4.126947450637817, Val Loss: 4.493733739852905\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 1.4118423461914062, Val Loss: 1.7220149278640746\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 1.4822630167007447, Val Loss: 1.7873604774475098\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 4.121628522872925, Val Loss: 4.479076480865478\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 4.129872798919678, Val Loss: 4.495632028579712\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 1.453694462776184, Val Loss: 1.7739856958389282\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 1.4678316354751586, Val Loss: 1.7890484571456908\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 4.122737979888916, Val Loss: 4.473272037506104\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 4.128268098831176, Val Loss: 4.4881470680236815\n",
      "Best Parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False, 'optimizer': 'SGD'}, Train Loss: 0.07320117354393005, Val Loss: 0.361407995223999\n",
      "Best combo: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False, 'optimizer': 'SGD'}, with values: (0.07320117354393005, 0.361407995223999)\n"
     ]
    }
   ],
   "source": [
    "layers=[\n",
    "        ('dense', 25),\n",
    "        ('dense', 50),\n",
    "        ('dense', 150)\n",
    "    ]\n",
    "grid(prev_best, layers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:42:11.776215Z",
     "start_time": "2024-01-17T12:49:45.368832300Z"
    }
   },
   "id": "96865d55fb40cded",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_to_test = keras_mlp([\n",
    "    ('dense', 25),\n",
    "    ('dense', 50),\n",
    "    ('dense', 150)\n",
    "])\n",
    "#Best combo: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True, 'optimizer': 'SGD'}, with values: (0.05887814909219742, 0.43884475231170655)\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, cooldown=10, verbose=1,\n",
    "                      factor=0.5,\n",
    "                      min_lr=1e-7,\n",
    "                      min_delta=1e-7),\n",
    "    EarlyStopping(monitor='val_loss', start_from_epoch=100, patience=20,\n",
    "                  min_delta=1e-7)\n",
    "]\n",
    "optim = k.optimizers.SGD(learning_rate=0.0045, momentum=0.9, weight_decay=0.000, nesterov=True)\n",
    "hst = keras_train(model_to_test, train_data=(X_train, y_train), val_data=(X_val, y_val), epochs=350, batch_size=50,\n",
    "                  optimizer=optim, callback=callbacks)\n",
    "plot_keras_history(hst, 20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T16:25:00.528530100Z",
     "start_time": "2024-01-17T16:25:00.522521700Z"
    }
   },
   "id": "47b628268cfe7a22",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer configuration: [('dense', 150), ('dense', 50), ('dense', 25)]\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.30129295587539673, Val Loss: 1.8313605546951295\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 2.388154983520508, Val Loss: 6.876751327514649\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.21715184450149536, Val Loss: 0.6317972481250763\n",
      "--------------------------------\n",
      "New best parameters\n",
      "--------------------------------\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.22023009955883027, Val Loss: 0.5733217179775238\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.26844403743743894, Val Loss: 1.4376553297042847\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 1.612425112724304, Val Loss: 5.804270267486572\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.2090540736913681, Val Loss: 0.6326398849487305\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.2168396681547165, Val Loss: 0.6171630024909973\n",
      "--------------------------------\n",
      "New best parameters\n",
      "--------------------------------\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.3583593338727951, Val Loss: 2.0035737276077272\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 1.752459454536438, Val Loss: 5.546025085449219\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.21525759100914002, Val Loss: 0.6823569059371948\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.2170933485031128, Val Loss: 0.5822800755500793\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.23707347214221955, Val Loss: 1.7246469020843507\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 2.388334584236145, Val Loss: 7.000948429107666\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.25707049369812013, Val Loss: 0.6366368055343627\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.19278585016727448, Val Loss: 0.5708501100540161\n",
      "--------------------------------\n",
      "New best parameters\n",
      "--------------------------------\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid(prev_best, [\n",
    "    ('dense', 150),\n",
    "    ('dense', 50),\n",
    "    ('dense', 25)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T16:24:54.173907Z",
     "start_time": "2024-01-17T13:42:11.775211200Z"
    }
   },
   "id": "fe268f998e3f5eb3",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_to_test = keras_mlp([\n",
    "    ('dense', 150),\n",
    "    ('dense', 50),\n",
    "    ('dense', 25)\n",
    "])\n",
    "\n",
    "optim = k.optimizers.SGD(learning_rate=0.01, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "\n",
    "hst = keras_train(model_to_test, train_data=(X_train, y_train), val_data=(X_val, y_val), epochs=150, batch_size=50,\n",
    "                  optimizer=optim, callback=callbacks)\n",
    "\n",
    "plot_keras_history(hst)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-17T16:25:00.520522900Z"
    }
   },
   "id": "80c4f89690b9d04",
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T16:29:30.202896300Z",
     "start_time": "2024-01-17T16:29:30.195895200Z"
    }
   },
   "id": "c6ef81bfe4c05ab6",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer configuration: [('dense', 300), ('dense', 300), ('dense', 300), ('dense', 300)]\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705577434.773231    1015 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.041876498982310294, Val Loss: 2.6961245059967043\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.01029393021017313, Val Loss: 1.6443861961364745\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.025222624838352203, Val Loss: 0.3496615529060364\n",
      "--------------------------------\n",
      "New best parameters\n",
      "--------------------------------\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.02818046696484089, Val Loss: 0.29553282260894775\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.1607966230250895, Val Loss: 2.1112640500068665\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.00924728373065591, Val Loss: 1.6987105369567872\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.018601242825388907, Val Loss: 0.37621089220047\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.02253647558391094, Val Loss: 0.26425916850566866\n",
      "--------------------------------\n",
      "New best parameters\n",
      "--------------------------------\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.07104927953332663, Val Loss: 2.9849231243133545\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.059911142010241746, Val Loss: 2.1923381805419924\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.02247847616672516, Val Loss: 0.46937898397445676\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.027053435519337653, Val Loss: 0.2812325060367584\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.7527022112160922, Val Loss: 5.45744571685791\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.037900120671838525, Val Loss: 1.8791339874267579\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.024396951869130136, Val Loss: 0.3299424558877945\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.03018488474190235, Val Loss: 0.24127809703350067\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.018473929911851882, Val Loss: 0.3005090355873108\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.012207567878067493, Val Loss: 0.37065669894218445\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.09957680255174636, Val Loss: 0.2749814629554749\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.08741692826151848, Val Loss: 0.25133840143680575\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.017295891232788563, Val Loss: 0.2555402398109436\n",
      "--------------------------------\n",
      "New best parameters\n",
      "--------------------------------\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.01378304734826088, Val Loss: 0.37977280020713805\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.09769110679626465, Val Loss: 0.28565434217453\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.1035308837890625, Val Loss: 0.2784379005432129\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.01730367112904787, Val Loss: 0.32322664856910704\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.01196964867413044, Val Loss: 0.3715541988611221\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.09891994297504425, Val Loss: 0.28787400424480436\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.09802828282117844, Val Loss: 0.2676285743713379\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.01725967451930046, Val Loss: 0.3315601110458374\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.012085715681314469, Val Loss: 0.4285210967063904\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.08481990098953247, Val Loss: 0.25633364617824556\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.09224074631929398, Val Loss: 0.2700388044118881\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.06579193770885468, Val Loss: 0.23873709440231322\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.06080764234066009, Val Loss: 0.2583603411912918\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.23223098516464233, Val Loss: 0.4293229103088379\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.1930414080619812, Val Loss: 0.36294071078300477\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.06544446498155594, Val Loss: 0.24883041977882386\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.0626378282904625, Val Loss: 0.2594903320074081\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.21485494673252106, Val Loss: 0.3967860102653503\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.20201955437660218, Val Loss: 0.3753657817840576\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.0640030026435852, Val Loss: 0.23674800395965576\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.07547097951173783, Val Loss: 0.2816579043865204\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.23412894308567048, Val Loss: 0.40066738724708556\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.19737273454666138, Val Loss: 0.37034661769866944\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.06425329819321632, Val Loss: 0.24636201560497284\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.059607142210006715, Val Loss: 0.25520946085453033\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.22291215062141417, Val Loss: 0.40089917182922363\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.16838952898979187, Val Loss: 0.33887365460395813\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.9153199911117553, Val Loss: 1.133232629299164\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.9121395230293274, Val Loss: 1.1152875781059266\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 2.8005505084991453, Val Loss: 3.1021267414093017\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 2.7927850246429444, Val Loss: 3.076761817932129\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.9216606855392456, Val Loss: 1.1292662024497986\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.9071994662284851, Val Loss: 1.1162750482559205\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 2.794458103179932, Val Loss: 3.0670941352844237\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 2.803559350967407, Val Loss: 3.083862638473511\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.9164979815483093, Val Loss: 1.1266622304916383\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.9071179866790772, Val Loss: 1.1221729516983032\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 2.794354057312012, Val Loss: 3.0904923915863036\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 2.7941235065460206, Val Loss: 3.078734827041626\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.9267808198928833, Val Loss: 1.1411383748054504\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.9063108086585998, Val Loss: 1.116133737564087\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 2.7987479686737062, Val Loss: 3.073078489303589\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 2.7918653964996336, Val Loss: 3.078834390640259\n",
      "Best Parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True, 'optimizer': 'SGD'}, Train Loss: 0.017295891232788563, Val Loss: 0.2555402398109436\n",
      "Best combo: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True, 'optimizer': 'SGD'}, with values: (0.017295891232788563, 0.2555402398109436)\n"
     ]
    }
   ],
   "source": [
    "grid(prev_best, [\n",
    "        ('dense', 300),\n",
    "        ('dense', 300),\n",
    "        ('dense', 300),\n",
    "        ('dense', 300)\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T12:30:16.898289300Z",
     "start_time": "2024-01-18T11:30:33.370286900Z"
    }
   },
   "id": "e3ddc94c1f77cef1",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer configuration: [('dense', 500), ('dense', 500), ('dense', 300), ('dense', 300), ('dense', 150)]\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 4.006334018707276, Val Loss: 12.30111904144287\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 2.2301490902900696, Val Loss: 9.267216873168945\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.031281442008912565, Val Loss: 1.2792925357818603\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.33110701814293864, Val Loss: 2.6364132881164553\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 4.559013509750367, Val Loss: 12.17245101928711\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 3.1172899484634398, Val Loss: 10.124323272705078\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.3542416483163834, Val Loss: 3.0003005981445314\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.24479114040732383, Val Loss: 2.7267481327056884\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 2.951116293668747, Val Loss: 9.96092414855957\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 8.153028106689453, Val Loss: 17.25533275604248\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 1.1034828267991543, Val Loss: 3.7106895565986635\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.2279082577675581, Val Loss: 2.533042472600937\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 103.36992177963256, Val Loss: 115.03928031921387\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 3.400139880180359, Val Loss: 10.396996593475341\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.18518919199705125, Val Loss: 2.461953949928284\n",
      "Training with parameters: {'learning_rate': 0.005, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.047460252046585084, Val Loss: 1.4858753681182861\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.013545753061771392, Val Loss: 0.8459376037120819\n",
      "--------------------------------\n",
      "New best parameters\n",
      "--------------------------------\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.22396817542612552, Val Loss: 2.250336694717407\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.035115742683410646, Val Loss: 0.4304028570652008\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.06057140305638313, Val Loss: 0.2785069316625595\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.4926201209425926, Val Loss: 2.9350017428398134\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.042263627983629704, Val Loss: 1.6859930992126464\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.05017234832048416, Val Loss: 0.3723041445016861\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.05206023305654526, Val Loss: 0.31167771220207213\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.36122188791632653, Val Loss: 2.981285834312439\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.018040880374610425, Val Loss: 1.1750672101974486\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.04636134132742882, Val Loss: 0.30226062536239623\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.06381282731890678, Val Loss: 0.27163389027118684\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.04209906496107578, Val Loss: 1.3283196926116942\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.042838936857879165, Val Loss: 1.8359384417533875\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.044198574125766756, Val Loss: 0.3750055551528931\n",
      "Training with parameters: {'learning_rate': 0.0025, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.05237315595149994, Val Loss: 0.24915768206119537\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.044287028908729556, Val Loss: 0.22670381665229797\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.0358116589486599, Val Loss: 0.2751829504966736\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.1744091257452965, Val Loss: 0.3507192134857178\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.15781269818544388, Val Loss: 0.34576826691627505\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.04493221268057823, Val Loss: 0.21428690254688262\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.04394207522273064, Val Loss: 0.2759702503681183\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.1644583076238632, Val Loss: 0.3497789025306702\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.1709773987531662, Val Loss: 0.356685197353363\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.04128877110779285, Val Loss: 0.22789767980575562\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.042502110823988914, Val Loss: 0.2751595675945282\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.1785951614379883, Val Loss: 0.3750101923942566\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.1428924545645714, Val Loss: 0.3371662735939026\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.051067807525396344, Val Loss: 0.25083989799022677\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.04427459761500359, Val Loss: 0.2640408307313919\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': True}\n",
      "Train Loss: 0.18115797340869905, Val Loss: 0.37273191213607787\n",
      "Training with parameters: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.75, 'nesterov': False}\n",
      "Train Loss: 0.14552053362131118, Val Loss: 0.3320301115512848\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': True}\n",
      "Train Loss: 0.5534581184387207, Val Loss: 0.7702643632888794\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'nesterov': False}\n",
      "Train Loss: 0.5539053440093994, Val Loss: 0.7694320678710938\n",
      "Training with parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.75, 'nesterov': True}\n"
     ]
    }
   ],
   "source": [
    "grid(prev_best, [\n",
    "        ('dense', 500),\n",
    "        ('dense', 500),\n",
    "        ('dense', 300),\n",
    "        ('dense', 300),\n",
    "        ('dense', 150),\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:30:16.891291Z"
    }
   },
   "id": "bfd22fa3a339d4dc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Best parameters: {'learning_rate': 0.005, 'weight_decay': 0.001, 'momentum': 0.9, 'nesterov': True, 'optimizer': 'SGD'}, with values: (18.03679656982422, 18.47313709259033)\n",
    "model_to_test = keras_mlp([\n",
    "    ('bn', 1),\n",
    "    ('dense', 300),\n",
    "    ('dense', 300),\n",
    "    ('dense', 300),\n",
    "    ('dense', 300)\n",
    "])\n",
    "model_to_test.summary()\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, cooldown=20, verbose=1,\n",
    "                      factor=0.25,\n",
    "                      min_lr=1e-7,\n",
    "                      min_delta=1e-7)\n",
    "]\n",
    "history = keras_train(model_to_test, train_data=(X_train, y_train), val_data=(X_val, y_val), epochs=150,\n",
    "                      optimizer=k.optimizers.SGD(learning_rate=0.005, momentum=0.9, weight_decay=0.001, nesterov=True),\n",
    "                      callback=callbacks)\n",
    "plot_keras_history(history)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-17T16:25:00.520522900Z"
    }
   },
   "id": "9ff7274805279b14",
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "model_to_test = keras_mlp([\n",
    "    ('dense', 350),\n",
    "    ('dense', 350),\n",
    "    ('dense', 150),\n",
    "    ('dense', 150),\n",
    "])\n",
    "\n",
    "\n",
    "def scheduler(epochs, lr):\n",
    "    newlr = lr\n",
    "    if epochs % 100 == 0:\n",
    "        newlr = lr * 0.5\n",
    "    return newlr\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    LearningRateScheduler(scheduler)\n",
    "]\n",
    "#Best combo: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True, 'optimizer': 'SGD'}, with values: (0.0807236298918724, 0.35102823972702024)\n",
    "\n",
    "optim = k.optimizers.SGD(learning_rate=0.001, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "hst = keras_train(model_to_test, train_data=(X_train, y_train), val_data=(X_val, y_val), epochs=350,\n",
    "                  optimizer=optim, callback=callbacks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-17T16:25:00.523521600Z"
    }
   },
   "id": "b2a580e850e748b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_keras_history(hst, 30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-17T16:25:00.523521600Z"
    }
   },
   "id": "4e7734c7ada71066",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-17T16:25:00.565529800Z"
    }
   },
   "id": "eaa1a7ba3d191a80",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-17T16:25:09.126896500Z"
    }
   },
   "id": "6a69341138b351f1",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
