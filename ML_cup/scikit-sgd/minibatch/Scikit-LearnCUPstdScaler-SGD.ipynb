{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lettura, understanding e preparazione dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import make_scorer\n",
    "# per visualizzare i dati in 3D\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# per rimuovere i warnings\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_tr = ['id', 'input_1', 'input_2', 'input_3', 'input_4', 'input_5', 'input_6', 'input_7', 'input_8', 'input_9', 'input_10', 'input_11', 'input_12', 'output_x', 'output_y', 'output_z']\n",
    "header_ts = ['id', 'input_1', 'input_2', 'input_3', 'input_4', 'input_5', 'input_6', 'input_7', 'input_8', 'input_9', 'input_10', 'input_11', 'input_12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path per fisso (TR)\n",
    "training_set_path = r'C:\\Users\\Giovanni\\Desktop\\Machine Learning (ML)\\new\\16-ML-24-PRJ lecture amp package-20250204\\ML-Working\\ML_course_stuffs\\ML-CUP24-TR.csv'\n",
    "# path per portatile (TR)\n",
    "# training_set_path = r'C:\\Users\\hp\\Desktop\\Machine Learning (ML)\\ML-Working\\data\\ML-CUP24-TR.csv'\n",
    "df_TR = pd.read_csv(training_set_path, comment='#', names=header_tr)\n",
    "\n",
    "# path per fisso (TS)\n",
    "test_set_path = r'C:\\Users\\Giovanni\\Desktop\\Machine Learning (ML)\\new\\16-ML-24-PRJ lecture amp package-20250204\\ML-Working\\ML_course_stuffs\\ML-CUP24-TS.csv'\n",
    "# path per portatile (TS)\n",
    "# test_set_path = r'C:\\Users\\hp\\Desktop\\Machine Learning (ML)\\ML-Working\\data\\ML-CUP24-TS.csv'\n",
    "df_TS = pd.read_csv(test_set_path, comment='#', names=header_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_TR.shape)\n",
    "print(df_TS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparazione dati\n",
    "X = df_TR.iloc[:, 1:-3]\n",
    "y = df_TR.iloc[:, -3:]\n",
    "\n",
    "X_blind_test = df_TS.iloc[:, 1:]\n",
    "# y_blind_test AKA blind test questo ce l'ha il prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- la *x* delle label ha un range tra -2.2 e 2.4\n",
    "- la *y* delle label ha un range tra -2.5 e 2\n",
    "- la *z* delle label ha un range tra -9.7 e 25.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lables del file di training della CUP in 3D\n",
    "\n",
    "y_array = y.to_numpy() \n",
    "\n",
    "X_coor = y_array[:, 0]  \n",
    "Y_coor = y_array[:, 1]  \n",
    "Z_coor = y_array[:, 2] \n",
    "\n",
    "# Creazione figura 3D\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot 3D\n",
    "ax.scatter(X_coor, Y_coor, Z_coor, c=Z_coor, cmap='coolwarm', marker='o')\n",
    "\n",
    "# Label assi\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "ax.set_title(\"Plot labels di training in 3D\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_blind_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_blind_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dei dati (dev e internal test set)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training + Validation Set (Dev Set): {len(X_dev)} campioni\")\n",
    "print(f\"Internal Test Set: {len(X_test)} campioni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_dev.shape)\n",
    "print(y_dev.shape)   \n",
    "print(X_test.shape)\n",
    "print(y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dei dati (train e val set)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training Set: {len(X_train)} campioni\")\n",
    "print(f\"Validation Set: {len(X_val)} campioni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)    \n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizzazione dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZZAZIONE CON STANDARD SCALER\n",
    "scaler_X, X_train_scaled, X_val_scaled, X_test_scaled, = StandardScalerFun(X_train, X_val, X_test)\n",
    "scaler_y, y_train_scaled, y_val_scaled, y_test_scaled = StandardScalerFun(y_train, y_val, y_test)\n",
    "\n",
    "# Normalizzazione blind\n",
    "columns_blind = X_blind_test.columns\n",
    "index_blind = X_blind_test.index\n",
    "X_blind_test_scaled_np = scaler_X.transform(X_blind_test)\n",
    "X_blind_test_scaled = pd.DataFrame(X_blind_test_scaled_np, columns=columns_blind, index=index_blind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ricreazione di X_dev dopo la normalizzazione\n",
    "X_dev_scaled = pd.concat([X_train_scaled, X_val_scaled])\n",
    "y_dev_scaled = pd.concat([y_train_scaled, y_val_scaled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allenamento con grid e internal test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling\n",
    "\n",
    "# NN per task di regressione\n",
    "mlp = MLPRegressor(max_iter=epochs, random_state=42,)\n",
    "\n",
    "# Creazione dello scorer personalizzato per MEE\n",
    "mee_scorer = make_scorer(mean_euclidean_error, greater_is_better=False)\n",
    "\n",
    "param_grid = [\n",
    "         {\n",
    "        'hidden_layer_sizes': [(3,), (50,), (5, 3), (50, 50), (100, 80), (10, 8, 5), (50, 50, 50), (200, 200, 200)],\n",
    "        'activation': ['tanh', 'relu'],  \n",
    "        'solver': ['sgd'], \n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1], \n",
    "        'learning_rate_init': [0.01, 0.02, 0.001, 0.002, 0.0001],\n",
    "        'learning_rate': ['constant', 'adaptive'],  \n",
    "        'batch_size': [16, 32, 64], # 1 -> online, 'auto' --> fullbatch, other --> minibatch\n",
    "        'momentum': [0.9, 0.95]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Creazione del K-Fold Cross Validation (5 fold)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Creazione di GridSearchCV usando MSE come scoring per il training\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1, refit=True)\n",
    "\n",
    "# Esecuzione Grid Search usando Training Set e Validation Set (AKA dev set)\n",
    "grid_search.fit(X_dev_scaled, y_dev_scaled)\n",
    "\n",
    "# Miglior modello trovato dalla Grid Search\n",
    "best_mlp = grid_search.best_estimator_\n",
    "\n",
    "# Calcolo del MEE medio con cross-validation sul miglior modello\n",
    "mee_scores = cross_val_score(best_mlp, X_dev, y_dev, cv=cv, scoring=mee_scorer, n_jobs=-1)\n",
    "\n",
    "# Migliori parametri trovati\n",
    "print(\"Migliori parametri trovati:\", grid_search.best_params_)\n",
    "print(\"MSE medio SCALATO (sui 5 fold) sul Validation:\", -grid_search.best_score_)\n",
    "print(\"MEE medio SCALATO (sui 5 fold) sul Validation:\", -np.mean(mee_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Grafico con scala lineare\n",
    "plt.subplot(1, 2, 1)  # (1 riga, 2 colonne, primo grafico)\n",
    "plt.plot(best_mlp.loss_curve_, label=\"MSE (Loss)\", color=\"blue\")\n",
    "plt.xlabel(\"Epoche\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Loss Curve scalata (Scala Lineare)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Grafico con scala logaritmica\n",
    "plt.subplot(1, 2, 2)  # (1 riga, 2 colonne, secondo grafico)\n",
    "plt.plot(best_mlp.loss_curve_, label=\"MSE (Loss)\", color=\"blue\")\n",
    "plt.xlabel(\"Epoche\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Loss Curve scalata (Scala Logaritmica)\")\n",
    "plt.yscale(\"log\")  # Imposta scala logaritmica\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\")  # Grid anche sui minori\n",
    "\n",
    "plt.tight_layout()  # Migliora la disposizione\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione miglior iperparametri\n",
    "params = grid_search.best_params_\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del dataframe contenente tutti i risultati della Grid Search\n",
    "cv_res_df = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione sull'Internal Test Set\n",
    "y_pred_test_scaled = best_mlp.predict(X_test_scaled)\n",
    "y_pred_test = scaler_y.inverse_transform(y_pred_test_scaled.reshape(-1, y_test.shape[1]))\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "test_mee = mean_euclidean_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"MSE sull'Internal Test Set: {test_mse:.5f}\")\n",
    "print(f\"MEE sull'Internal Test Set: {test_mee:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot delle predizioni in 3D scalate e non (internal test)\n",
    "\n",
    "X1 = y_pred_test_scaled[:, 0] \n",
    "Y1 = y_pred_test_scaled[:, 1]  \n",
    "Z1 = y_pred_test_scaled[:, 2]  \n",
    "\n",
    "X2 = y_pred_test[:, 0]  \n",
    "Y2 = y_pred_test[:, 1]  \n",
    "Z2 = y_pred_test[:, 2]  \n",
    "\n",
    "\n",
    "# Creazione figure 3D\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax1 = fig.add_subplot(122, projection='3d')\n",
    "ax2 = fig.add_subplot(121, projection='3d')\n",
    "\n",
    "# Scatter plot 3D\n",
    "ax1.scatter(X1, Y1, Z1, c=Z1, cmap='coolwarm', marker='o')\n",
    "ax2.scatter(X2, Y2, Z2, c=Z2, cmap='coolwarm', marker='o')\n",
    "\n",
    "# Label assi\n",
    "ax1.set_xlabel(\"X\")\n",
    "ax1.set_ylabel(\"Y\")\n",
    "ax1.set_zlabel(\"Z\")\n",
    "ax1.set_title(\"Internal Test (StandardScaler) in 3D\")\n",
    "\n",
    "ax2.set_xlabel(\"X\")\n",
    "ax2.set_ylabel(\"Y\")\n",
    "ax2.set_zlabel(\"Z\")\n",
    "ax2.set_title(\"Internal Test in 3D\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_blind_test_pred_scaled= best_mlp.predict(X_blind_test_scaled)\n",
    "y_blind_test_pred = scaler_y.inverse_transform(y_blind_test_pred_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_blind_test_pred_scaled.shape)\n",
    "print(y_blind_test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot delle predizioni in 3D scalate e non (blind test)\n",
    "\n",
    "X1 = y_blind_test_pred_scaled[:, 0]  \n",
    "Y1 = y_blind_test_pred_scaled[:, 1]  \n",
    "Z1 = y_blind_test_pred_scaled[:, 2] \n",
    "\n",
    "X2 = y_blind_test_pred[:, 0]  \n",
    "Y2 = y_blind_test_pred[:, 1]  \n",
    "Z2 = y_blind_test_pred[:, 2]  \n",
    "\n",
    "\n",
    "# Creazione figura 3D\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax1 = fig.add_subplot(122, projection='3d')\n",
    "ax2 = fig.add_subplot(121, projection='3d')\n",
    "\n",
    "# Scatter plot 3D\n",
    "ax1.scatter(X1, Y1, Z1, c=Z1, cmap='coolwarm', marker='o')\n",
    "ax2.scatter(X2, Y2, Z2, c=Z2, cmap='coolwarm', marker='o')\n",
    "\n",
    "# Label assi\n",
    "ax1.set_xlabel(\"X\")\n",
    "ax1.set_ylabel(\"Y\")\n",
    "ax1.set_zlabel(\"Z\")\n",
    "ax1.set_title(\"Blind test (StandardScaler) in 3D\")\n",
    "\n",
    "ax2.set_xlabel(\"X\")\n",
    "ax2.set_ylabel(\"Y\")\n",
    "ax2.set_zlabel(\"Z\")\n",
    "ax2.set_title(\"Blind test in 3D\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione miglior iperparametri\n",
    "best_params = grid_search.best_params_\n",
    "best_params\n",
    "\n",
    "best_params = {'activation': 'relu',\n",
    " 'alpha': 0.001,\n",
    " 'batch_size': 64,\n",
    " 'hidden_layer_sizes': (50, 50),\n",
    " 'learning_rate': 'constant',\n",
    " 'learning_rate_init': 0.02,\n",
    " 'momentum': 0.9,\n",
    " 'solver': 'sgd'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 run diverse corrispondenti a 5 random_state differenti (MODEL SELECTION)\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "# Seed differenti\n",
    "random_states = [7, 13, 26, 39, 47]\n",
    "\n",
    "for rs in random_states:\n",
    "    print(f\"Training con random_state={rs}...\")\n",
    "\n",
    "    # Inizializzazione modello con i miglior iperparametri trovati\n",
    "    nn = MLPRegressor(\n",
    "        hidden_layer_sizes=best_params['hidden_layer_sizes'],\n",
    "        activation=best_params['activation'],\n",
    "        solver='sgd',\n",
    "        alpha=best_params['alpha'],\n",
    "        learning_rate_init=best_params['learning_rate_init'],\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        momentum=best_params['momentum'],\n",
    "        batch_size=64,  # fullbatch (64)\n",
    "        max_iter=1, # nota bene\n",
    "        warm_start=True, # nota bene\n",
    "        shuffle=True,\n",
    "        random_state=rs,\n",
    "        verbose=False\n",
    "      )\n",
    "\n",
    "    train_mse_list = []\n",
    "    val_mse_list = []\n",
    "    train_mee_list = []\n",
    "    val_mee_list = []\n",
    "\n",
    "    patience = 30  # Numero di epoche senza miglioramenti prima di fermarsi\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0  \n",
    "\n",
    "    for epoch in range(epochs):  \n",
    "        nn.partial_fit(X_train_scaled, y_train_scaled)\n",
    "        \n",
    "        # Predizioni su training e test set\n",
    "        y_train_pred_scaled = nn.predict(X_train_scaled)\n",
    "        y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled)\n",
    "        y_val_pred_scaled = nn.predict(X_val_scaled)\n",
    "        y_val_pred = scaler_y.inverse_transform(y_val_pred_scaled)\n",
    "\n",
    "        # Calcolo metriche     \n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "        train_mee = mean_euclidean_error(y_train, y_train_pred)\n",
    "        val_mee = mean_euclidean_error(y_val, y_val_pred)\n",
    "\n",
    "        # Memorizziamo i valori di loss e accuracy\n",
    "        train_mse_list.append(train_mse)    \n",
    "        val_mse_list.append(val_mse)\n",
    "        train_mee_list.append(train_mee)\n",
    "        val_mee_list.append(val_mee)\n",
    "\n",
    "        if val_mse < best_val_loss:\n",
    "            best_val_loss = val_mse\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # Creazione della figura con due subplot\n",
    "    fig, ax1 = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Plot MSE\n",
    "    ax1[0].plot(train_mse_list, label=\"Train MSE\", color=\"blue\")\n",
    "    ax1[0].plot(val_mse_list, label=\"Validation MSE\", color=\"green\")\n",
    "    ax1[0].set_xlabel(\"Epochs\")\n",
    "    ax1[0].set_ylabel(\"MSE\")\n",
    "    ax1[0].set_title(f\"MSE CUP (random_state={rs})\")\n",
    "    ax1[0].legend()\n",
    "    ax1[0].grid(True)\n",
    "\n",
    "    # Plot Accuracy\n",
    "    ax1[1].plot(train_mee_list, label=\"Train MEE\", color=\"blue\")\n",
    "    ax1[1].plot(val_mee_list, label=\"Validation MEE\", color=\"green\")\n",
    "    ax1[1].set_xlabel(\"Epochs\")\n",
    "    ax1[1].set_ylabel(\"MEE\")\n",
    "    ax1[1].set_title(f\"MEE CUP (random_state={rs})\")\n",
    "    ax1[1].legend()\n",
    "    ax1[1].grid(True)\n",
    "\n",
    "    # Mostra la figura completa con i due subplot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # print(f'Best params: {best_params}')\n",
    "    # Stampa dei risultati finali per ogni seed\n",
    "    print(f\"Risultati per random_state={rs}:\")\n",
    "    print(f\"  - Train MSE: {train_mse_list[-1]:.5f}, Validation MSE: {val_mse_list[-1]:.5f}\")\n",
    "    print(f\"  - Train MEE: {train_mee_list[-1]:.5f}, Validation MEE: {val_mee_list[-1]:.5f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Training Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione miglior iperparametri\n",
    "best_params = grid_search.best_params_\n",
    "best_params\n",
    "\n",
    "best_params = {'activation': 'relu',\n",
    " 'alpha': 0.001,\n",
    " 'batch_size': 64,\n",
    " 'hidden_layer_sizes': (50, 50),\n",
    " 'learning_rate': 'constant',\n",
    " 'learning_rate_init': 0.02,\n",
    " 'momentum': 0.9,\n",
    " 'solver': 'sgd'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del miglior modello con gli iperparametri trovati\n",
    "best_mlp = MLPRegressor(\n",
    "    hidden_layer_sizes=best_params['hidden_layer_sizes'],\n",
    "    activation=best_params['activation'],\n",
    "    solver='sgd',\n",
    "    alpha=best_params['alpha'],\n",
    "    learning_rate_init=best_params['learning_rate_init'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    momentum=best_params['momentum'],\n",
    "    batch_size=64,  # fullbatch (64)\n",
    "    max_iter=1,  # nota bene\n",
    "    warm_start=True, # nota bene\n",
    "    shuffle=True,\n",
    "    random_state=39,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "\n",
    "train_mse_list = []\n",
    "test_mse_list = []\n",
    "train_mee_list = []\n",
    "test_mee_list = [] \n",
    "\n",
    "for epoch in range(epochs):  \n",
    "    # Allenamento sul training set\n",
    "    best_mlp.partial_fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "    # Predizioni su training e test set\n",
    "    y_train_pred_scaled = best_mlp.predict(X_train_scaled) \n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled)  \n",
    "    y_test_pred_scaled = best_mlp.predict(X_test_scaled) \n",
    "    y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled)  \n",
    "\n",
    "    # Calcolo delle metriche\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "    train_mee = mean_euclidean_error(y_train, y_train_pred)\n",
    "    test_mee = mean_euclidean_error(y_test, y_test_pred)\n",
    "\n",
    "    # Memorizziamo i valori di MSE e MEE\n",
    "    train_mse_list.append(train_mse)    \n",
    "    test_mse_list.append(test_mse)\n",
    "    train_mee_list.append(train_mee)\n",
    "    test_mee_list.append(test_mee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione della figura con due subplot\n",
    "fig, ax1 = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot MSE\n",
    "ax1[0].plot(train_mse_list, label=\"Train MSE\", color=\"blue\")\n",
    "ax1[0].plot(test_mse_list, label=\"Test MSE\", color=\"red\")\n",
    "ax1[0].set_xlabel(\"Epochs\")\n",
    "ax1[0].set_ylabel(\"MSE\")\n",
    "ax1[0].set_title(f\"MSE CUP\")\n",
    "ax1[0].legend()\n",
    "ax1[0].grid(True)\n",
    "\n",
    "# Plot MEE\n",
    "ax1[1].plot(train_mee_list, label=\"Train MEE\", color=\"blue\")\n",
    "ax1[1].plot(test_mee_list, label=\"Test MEE\", color=\"red\")\n",
    "ax1[1].set_xlabel(\"Epochs\")\n",
    "ax1[1].set_ylabel(\"MEE\")\n",
    "ax1[1].set_title(f\"MEE CUP\")\n",
    "ax1[1].legend()\n",
    "ax1[1].grid(True)\n",
    "\n",
    "# Figura completa con i due subplot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"  - Train MSE: {train_mse_list[-1]:.5f}, Test MSE: {test_mse_list[-1]:.5f}\")\n",
    "print(f\"  - Train MEE: {train_mee_list[-1]:.5f}, Test MEE: {test_mee_list[-1]:.5f}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione sull'Internal Test Set\n",
    "y_pred_test_scaled = best_mlp.predict(X_test_scaled)\n",
    "y_pred_test = scaler_y.inverse_transform(y_pred_test_scaled.reshape(-1, y_test.shape[1]))\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "test_mee = mean_euclidean_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"MSE Internal Test: {test_mse}\")\n",
    "print(f\"MEE Internal Test: {test_mee}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot delle predizioni in 3D (internal test)\n",
    "\n",
    "X = y_pred_test[:, 0]  \n",
    "Y = y_pred_test[:, 1]  \n",
    "Z = y_pred_test[:, 2] \n",
    "\n",
    "# Creazione figura 3D\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot 3D\n",
    "ax.scatter(X, Y, Z, c=Z, cmap='coolwarm', marker='o')\n",
    "\n",
    "# Label assi\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "ax.set_title(\"Internal Test in 3D\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_blind_test_pred_scaled= best_mlp.predict(X_blind_test_scaled)\n",
    "y_blind_test_pred = scaler_y.inverse_transform(y_blind_test_pred_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_blind_test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot delle predizioni in 3D (blind test)\n",
    "\n",
    "X = y_blind_test_pred[:, 0]  \n",
    "Y = y_blind_test_pred[:, 1]  \n",
    "Z = y_blind_test_pred[:, 2] \n",
    "\n",
    "# Creazione figura 3D\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot 3D\n",
    "ax.scatter(X, Y, Z, c=Z, cmap='coolwarm', marker='o')\n",
    "\n",
    "# Label assi\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "ax.set_title(\"Blind Test in 3D\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
