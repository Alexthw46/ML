{
 "cells": [
  {
   "cell_type": "code",
   "id": "f70de84078ce5a85",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import dataset_utils as dataset\n",
    "import torch as t\n",
    "\n",
    "from ML_cup.pytorch import *"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    torch.set_default_device(torch.device(\"cuda\"))\n",
    "print(f\"Using device: {torch.cuda.current_device()}\")\n",
    "print(f\"Available cpu count: {os.cpu_count()}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1762c3fd3c36db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the data\n",
    "dev_data = dataset.load_dataset(\"../data/ML-CUP24-TR.csv\")\n",
    "blind_data = dataset.load_dataset(\"../data/ML-CUP24-TS.csv\")"
   ],
   "id": "183bfff084c3f33b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "# get a seed for the random state based on the current time\n",
    "rand = int(time.time())\n",
    "print(f\"Random seed: {rand}\")\n",
    "np.random.seed(rand)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# rescale the data\n",
    "dev_data, X_scaler, y_scaler = dataset.rescale_dataset(dev_data)\n",
    "blind_data = dataset.rescale_dataset(blind_data, X_scaler)\n",
    "\n",
    "# plot the dev data's targets on xyz axis\n",
    "# the targets are the last 3 columns of the data\n",
    "y = np.array(dev_data)[:, -3:]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(y[:, 0], y[:, 1], y[:, 2])\n",
    "plt.show()"
   ],
   "id": "e4c73463fd116be3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Definitions",
   "id": "7173757eb589ad38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def MLP() -> t.nn.Module:\n",
    "    return t.nn.Sequential(\n",
    "        t.nn.Linear(12, 200),\n",
    "        t.nn.Tanh(),\n",
    "        t.nn.Linear(200, 200),\n",
    "        t.nn.Tanh(),\n",
    "        t.nn.Linear(200, 3)\n",
    "    )\n",
    "\n",
    "def MLPr() -> t.nn.Module:\n",
    "    return t.nn.Sequential(\n",
    "        t.nn.Linear(12, 200),\n",
    "        t.nn.ReLU(),\n",
    "        t.nn.Linear(200, 200),\n",
    "        t.nn.ReLU(),\n",
    "        t.nn.Linear(200, 3)\n",
    "    )\n",
    "\n",
    "# v2, same depth, more neurons per layer. 300 neurons per layer\n",
    "# Test with more than this amount didn't show any improvement\n",
    "def MLPv2r() -> t.nn.Module:\n",
    "    return t.nn.Sequential(\n",
    "        t.nn.Linear(12, 300),\n",
    "        t.nn.ReLU(),\n",
    "        t.nn.Linear(300, 300),\n",
    "        t.nn.ReLU(),\n",
    "        t.nn.Linear(300, 3)\n",
    "    )\n",
    "\n",
    "\n",
    "def MLPv2() -> t.nn.Module:\n",
    "    return t.nn.Sequential(\n",
    "        t.nn.Linear(12, 300),\n",
    "        t.nn.Tanh(),\n",
    "        t.nn.Linear(300, 300),\n",
    "        t.nn.Tanh(),\n",
    "        t.nn.Linear(300, 3)\n",
    "    )\n",
    "\n",
    "# v3, more depth but a different structure. Increasing number of neurons at each layer, didn't show any improvement\n",
    "def MLPv3() -> t.nn.Module:\n",
    "    return t.nn.Sequential(\n",
    "        t.nn.Linear(12, 100),\n",
    "        t.nn.Tanh(),\n",
    "        t.nn.Linear(100, 200),\n",
    "        t.nn.Tanh(),\n",
    "        t.nn.Linear(200, 300),\n",
    "        t.nn.Tanh(),\n",
    "        t.nn.Linear(300, 3)\n",
    "    )\n",
    "\n",
    "def MLPv3r() -> t.nn.Module:\n",
    "    return t.nn.Sequential(\n",
    "        t.nn.Linear(12, 100),\n",
    "        t.nn.ReLU(),\n",
    "        t.nn.Linear(100, 200),\n",
    "        t.nn.ReLU(),\n",
    "        t.nn.Linear(200, 300),\n",
    "        t.nn.ReLU(),\n",
    "        t.nn.Linear(300, 3)\n",
    "    )\n",
    "\n",
    "# v4, same depth as v2, but less neurons per layer. 50 neurons per layer\n",
    "def MLPv4() -> t.nn.Module:\n",
    "    return t.nn.Sequential(\n",
    "        t.nn.Linear(12, 50),\n",
    "        t.nn.Tanh(),\n",
    "        t.nn.Linear(50, 50),\n",
    "        t.nn.Tanh(),\n",
    "        t.nn.Linear(50, 3)\n",
    "    )\n",
    "\n",
    "\n",
    "def MLPv4r() -> t.nn.Module:\n",
    "    return t.nn.Sequential(\n",
    "        t.nn.Linear(12, 50),\n",
    "        t.nn.ReLU(),\n",
    "        t.nn.Linear(50, 50),\n",
    "        t.nn.ReLU(),\n",
    "        t.nn.Linear(50, 3)\n",
    "    )"
   ],
   "id": "95df258f1fba028d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Grid search for the best parameters",
   "id": "b73e08884c560a83"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FullBatch",
   "id": "1c9459a4d4bc51da"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "code",
   "source": [
    "# Split the dev data into train and validation with k-fold cross validation\n",
    "train_loaders, val_loaders, dev_loader, test_loader = dataset.torch_k_fold(dataset=dev_data, folds=5, batch_size=0,\n",
    "                                                                           random_state=rand)\n",
    "# blind test\n",
    "from ML_cup.dataset_utils import CupDataset\n",
    "\n",
    "blind_loader = DataLoader(CupDataset(blind_data, device=torch.device('cuda')), batch_size=len(blind_data))"
   ],
   "id": "428a2e865c4e5640",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model v1\n",
    "For this model we split the parameters into two groups, one for the SGD optimizer and one for the Adam optimizer to split the execution cells, as we needed a better look at the results in tensorboard."
   ],
   "id": "486440e04ca21025"
  },
  {
   "cell_type": "code",
   "source": [
    "# Here we split the parameters into two groups, one for the SGD optimizer and one for the Adam optimizer to split the execution cells\n",
    "parameters_SGD = [\n",
    "    {\n",
    "        'optimizer': 'SGD',\n",
    "        'lr': np.linspace(0.0005, 0.0001, 5),\n",
    "        'weight_decay': [0.001, 0.0025, 0.005],\n",
    "        'momentum': [0.8, 0.9, 0.95],\n",
    "        'nesterov': [True, False]\n",
    "    }]\n",
    "parameters_Adam = [\n",
    "    {\n",
    "        'optimizer': 'Adam',\n",
    "        'lr': np.linspace(0.0002, 0.0001, 10),\n",
    "        'weight_decay': np.linspace(0.0001, 0.0005, 5)\n",
    "    }\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d7410d6d901e0af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SGD",
   "id": "17fb6a2e1710b27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# perform grid search to find the best parameters\n",
    "best_pytorch_params_s, model = grid_search(model_builder=MLP, parameters=parameters_SGD, random_seed=rand,\n",
    "                                           train_loader=train_loaders,\n",
    "                                           val_loader=val_loaders, max_epochs=1000,\n",
    "                                           scheduler=('', {}),\n",
    "                                           stability_threshold=1e-6, patience=5,\n",
    "                                           clip=1.0,\n",
    "                                           tensorboard_folder_base=f'runs/fullbatch/MLP/scaled/SGD/tanh/{rand}',\n",
    "                                           y_scaler=y_scaler)"
   ],
   "id": "fe4e14d6b7dfbd35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Adam",
   "id": "ca0c06f4af8df2d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# perform grid search to find the best parameters\n",
    "best_pytorch_params_a, model = grid_search(model_builder=MLP, parameters=parameters_Adam, random_seed=rand,\n",
    "                                           train_loader=train_loaders,\n",
    "                                           val_loader=val_loaders, max_epochs=1000,\n",
    "                                           scheduler=('', {}),\n",
    "                                           stability_threshold=1e-5, patience=5,\n",
    "                                           clip=1.0,\n",
    "                                           tensorboard_folder_base=f'runs/fullbatch/MLP/scaled/Adam/tanh/{rand}',\n",
    "                                           y_scaler=y_scaler)"
   ],
   "id": "fe0f502b5a261e56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model v2",
   "id": "61e462e526c9666"
  },
  {
   "cell_type": "code",
   "source": [
    "parameters = [\n",
    "    {\n",
    "        'optimizer': 'SGD',\n",
    "        'lr': np.linspace(0.005, 0.001, 5),\n",
    "        'weight_decay': [0.001, 0.005, 0.0015, 0.0025],\n",
    "        'momentum': [0.8, 0.9, 0.95],\n",
    "        'nesterov': [True, False]\n",
    "    },\n",
    "    {\n",
    "        'optimizer': 'Adam',\n",
    "        'lr': np.linspace(0.0005, 0.0001, 5),\n",
    "        'weight_decay': [0.0, 0.001, 0.0005]\n",
    "    }\n",
    "]"
   ],
   "metadata": {},
   "id": "aba90f6850025faa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "code",
   "source": [
    "# perform grid search to find the best parameters\n",
    "best_pytorch_params, model = grid_search(model_builder=MLPv2, parameters=parameters, train_loader=train_loaders,\n",
    "                                         val_loader=val_loaders, scheduler=('', {}),\n",
    "                                         patience=20, clip=1.0, stability_threshold=2e-4, max_epochs=1500,\n",
    "                                         tensorboard_folder_base=f'runs/fullbatch/MLP2/scaled/tanh/{rand}',\n",
    "                                         random_seed=rand, y_scaler=y_scaler)\n",
    "print(best_pytorch_params)\n"
   ],
   "id": "c5d17590b89cb895",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# perform grid search to find the best parameters\n",
    "best_pytorch_params, model = grid_search(model_builder=MLPv2r, parameters=parameters, train_loader=train_loaders,\n",
    "                                         val_loader=val_loaders, scheduler=('', {}),\n",
    "                                         patience=20, clip=1.0, stability_threshold=2e-4, max_epochs=1500,\n",
    "                                         tensorboard_folder_base=f'runs/fullbatch/MLP2r/scaled/relu/{rand}',\n",
    "                                         random_seed=rand, y_scaler=y_scaler)\n",
    "print(best_pytorch_params)"
   ],
   "id": "ba81d45d8287f8b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model v3",
   "id": "ea5932e14cd703b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# perform grid search to find the best parameters\n",
    "best_pytorch_params, model = grid_search(model_builder=MLPv3, parameters=parameters, train_loader=train_loaders,\n",
    "                                         val_loader=val_loaders,\n",
    "                                         scheduler=('', {}),\n",
    "                                         clip=1.0, max_epochs=1500,\n",
    "                                         stability_threshold=5e-4, patience=20,\n",
    "                                         tensorboard_folder_base=f'runs/fullbatch/MLP3/scaled/tanh/{rand}',\n",
    "                                         random_seed=rand, y_scaler=y_scaler)\n",
    "print(best_pytorch_params)"
   ],
   "id": "f9513b6b3a994c83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model v4",
   "id": "8765b57521c19bae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#perform grid search to find the best parameters\n",
    "best_pytorch_params, model = grid_search(model_builder=MLPv4, parameters=parameters, train_loader=train_loaders,\n",
    "                                         val_loader=val_loaders,\n",
    "                                         scheduler=('', {}),\n",
    "                                         clip=1.0, max_epochs=1500,\n",
    "                                         stability_threshold=0.1, patience=20,\n",
    "                                         tensorboard_folder_base=f'runs/fullbatch/MLP4/scaled/{rand}',\n",
    "                                         random_seed=rand, y_scaler=y_scaler)"
   ],
   "id": "6474501c3b5dc99b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Minibatch",
   "id": "bae02f851f0d413e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split the dev data into train and validation with k-fold cross validation\n",
    "train_loaders, val_loaders, dev_loader, test_loader = dataset.torch_k_fold(dataset=dev_data, folds=5, batch_size=20,\n",
    "                                                                           random_state=rand)\n",
    "# blind test\n",
    "from ML_cup.dataset_utils import CupDataset\n",
    "\n",
    "blind_loader = DataLoader(CupDataset(blind_data, device=torch.device('cuda')))"
   ],
   "id": "dcd1851949132cb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model v1\n",
    "For this model we split the parameters into two groups, one for the SGD optimizer and one for the Adam optimizer to split the execution cells, as we needed a better look at the results in tensorboard."
   ],
   "id": "512bf24b5d090dba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SGD",
   "id": "ff733e197a060f9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "parameters = [\n",
    "    {\n",
    "        'optimizer': 'SGD',\n",
    "        'lr': np.linspace(0.0075, 0.000075, 5),\n",
    "            'weight_decay': np.linspace(0.01, 0.00001, 5),\n",
    "        'momentum': [0.9, 0.95, 0.8],\n",
    "        'nesterov': [True, False]\n",
    "    }\n",
    "]\n",
    "# perform grid search to find the best parameters\n",
    "best_pytorch_params, best_model = grid_search(model_builder=MLP, parameters=parameters, random_seed=rand,\n",
    "                                              train_loader=train_loaders,\n",
    "                                              val_loader=val_loaders, max_epochs=1500,\n",
    "                                              scheduler=('', {}),\n",
    "                                              stability_threshold=0.25, patience=10,\n",
    "                                              clip=1.0,\n",
    "                                              tensorboard_folder_base=f'runs/minibatch/MLP/SGD/scaled/tanh/{rand}',\n",
    "                                              y_scaler=y_scaler)"
   ],
   "id": "20cc9130377b62dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Adam",
   "id": "88a35fecba884eca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "parameters = [\n",
    "    {\n",
    "        'optimizer': 'Adam',\n",
    "        'lr': np.linspace(0.0005, 0.0001, 10),\n",
    "        'weight_decay': np.linspace(0.001, 0.00001, 10),\n",
    "    }]\n",
    "\n",
    "best_pytorch_params, best_model = grid_search(model_builder=MLP, parameters=parameters, random_seed=rand,\n",
    "                                              train_loader=train_loaders, val_loader=val_loaders,\n",
    "                                              scheduler=('', {}), max_epochs=1500,\n",
    "                                              stability_threshold=0.25, patience=10,\n",
    "                                              clip=1.0,\n",
    "                                              tensorboard_folder_base=f'runs/minibatch/MLP/Adam/scaled/tanh/{rand}',\n",
    "                                              y_scaler=y_scaler)\n",
    "# retrain the model with the best parameters on the whole dataset\n",
    "print(best_pytorch_params)\n",
    "model_v1 = best_model\n",
    "# Evaluate the trained model on the test set\n",
    "print(\"Evaluating the model on the test set\")\n",
    "print(torch_predict(model_v1, test_loader))\n",
    "\n",
    "blind_test(model_v1, blind_loader, rand, y_scaler=y_scaler)"
   ],
   "id": "97f01084257e3d07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model v2",
   "id": "e5dfbf38a3f3f171"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Relu",
   "id": "76dfbf813151040"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "parameters = [\n",
    "    {\n",
    "        'optimizer': 'SGD',\n",
    "        'lr': np.linspace(0.0025, 0.0001, 5),\n",
    "        'weight_decay': [0.001, 0.005, 0.0015, 0.0025],\n",
    "        'momentum': [0.9, 0.95],\n",
    "        'nesterov': [True]\n",
    "    },\n",
    "    {\n",
    "        'optimizer': 'Adam',\n",
    "        'lr': np.linspace(0.0003, 0.000075, 10),\n",
    "        'weight_decay': np.linspace(0.0001, 0.0005, 10),\n",
    "    }\n",
    "]\n",
    "\n",
    "best_pytorch_params, best_model = grid_search(model_builder=MLPv2r, parameters=parameters, random_seed=rand,\n",
    "                                              train_loader=train_loaders, val_loader=val_loaders,\n",
    "                                              scheduler=('', {}), max_epochs=1500,\n",
    "                                              stability_threshold=0.25, patience=10,\n",
    "                                              clip=1.0, tensorboard_folder_base=f'runs/minibatch/MLP2/scaled/relu/{rand}',\n",
    "                                              y_scaler=y_scaler)\n",
    "print(best_pytorch_params, best_model)"
   ],
   "id": "e18bc12d1db3b4fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tanh",
   "id": "4c76da7df9619dd1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "parameters = [\n",
    "    {\n",
    "        'optimizer': 'SGD',\n",
    "        'lr': np.linspace(0.0025, 0.0001, 5),\n",
    "        'weight_decay': [0.001, 0.005, 0.0015, 0.0025],\n",
    "        'momentum': [0.9, 0.95],\n",
    "        'nesterov': [True]\n",
    "    },\n",
    "    {\n",
    "        'optimizer': 'Adam',\n",
    "        'lr': np.linspace(0.0003, 0.000075, 10),\n",
    "        'weight_decay': np.linspace(0.0001, 0.0005, 10),\n",
    "    }\n",
    "]\n",
    "\n",
    "# perform grid search to find the best parameters\n",
    "best_pytorch_params, best_model = grid_search(model_builder=MLPv2, parameters=parameters, train_loader=train_loaders,\n",
    "                                              val_loader=val_loaders, scheduler=('', {}), max_epochs=1500,\n",
    "                                              patience=20, clip=1.0, stability_threshold=0.2,\n",
    "                                              tensorboard_folder_base=f'runs/minibatch/MLP2/scaled/tanh/{rand}',\n",
    "                                              random_seed=rand, y_scaler=y_scaler)\n",
    "print(best_pytorch_params)"
   ],
   "id": "368535e32b40437c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model v3",
   "id": "237e76cb981df133"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "parameters_sgd3 = [\n",
    "    {\n",
    "        'optimizer': 'SGD',\n",
    "        'lr': np.linspace(0.00075, 0.0001, 5),\n",
    "        'weight_decay': [0.001, 0.0005, 0.0015, 0.0025],\n",
    "        'momentum': [0.8, 0.9],\n",
    "        'nesterov': [True]\n",
    "    }]\n",
    "parameters_adam3 = [\n",
    "    {\n",
    "        'optimizer': 'Adam',\n",
    "        'lr': np.linspace(0.000025, 0.0000075, 5),\n",
    "        'weight_decay': np.linspace(0.0001, 0.00005, 10)\n",
    "    }]"
   ],
   "id": "35b2e599ff7be480",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# perform grid search to find the best parameters\n",
    "best_pytorch_params, model_v3 = grid_search(model_builder=MLPv3, parameters=parameters_sgd3,\n",
    "                                            train_loader=train_loaders,\n",
    "                                            val_loader=val_loaders,\n",
    "                                            scheduler=('', {}),\n",
    "                                            clip=1.0, max_epochs=1500,\n",
    "                                            stability_threshold=5e-5, patience=20,\n",
    "                                            tensorboard_folder_base=f'runs/minibatch/MLP3/scaled/SGD/{rand}',\n",
    "                                            random_seed=rand, y_scaler=y_scaler)\n",
    "# retrain the model with the best parameters\n",
    "# best_pytorch_params = {'lr': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'nesterov': True, 'optimizer': 'SGD'}\n",
    "print(best_pytorch_params)"
   ],
   "id": "a044f29af4ff1407",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# perform grid search to find the best parameters\n",
    "best_pytorch_params, model_v3 = grid_search(model_builder=MLPv3, parameters=parameters_adam3,\n",
    "                                            train_loader=train_loaders,\n",
    "                                            val_loader=val_loaders,\n",
    "                                            scheduler=('', {}),\n",
    "                                            clip=1.0, max_epochs=1500,\n",
    "                                            stability_threshold=5e-5, patience=20,\n",
    "                                            tensorboard_folder_base=f'runs/minibatch/MLP3/scaled/Adam/{rand}',\n",
    "                                            random_seed=rand, y_scaler=y_scaler)\n",
    "# retrain the model with the best parameters\n",
    "# best_pytorch_params = {'lr': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'nesterov': True, 'optimizer': 'SGD'}\n",
    "print(best_pytorch_params)"
   ],
   "id": "9b9bf1397e4832e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model v4",
   "id": "c41c0022bb32a444"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#perform grid search to find the best parameters\n",
    "best_pytorch_params, model = grid_search(model_builder=MLPv4, parameters=parameters, train_loader=train_loaders,\n",
    "                                         val_loader=val_loaders,\n",
    "                                         scheduler=('', {}),\n",
    "                                         clip=1.0, max_epochs=1500,\n",
    "                                         stability_threshold=0.1, patience=20,\n",
    "                                         tensorboard_folder_base=f'runs/minibatch/MLP4/scaled/{rand}',\n",
    "                                         random_seed=rand, y_scaler=y_scaler)"
   ],
   "id": "73f113bdbf2bbcca",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
